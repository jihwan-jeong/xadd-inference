\begin{abstract}
\begin{quote}
Probabilistic inference in many real-world problems requires graphical models with deterministic algebraic constraints between random variables (e.g., Newtonian mechanics, Pascal's law, Ohm's law) that are known to be problematic for many inference methods such as 
Monte Carlo sampling. Fortunately, when such constraints are invertible, the model can be collapsed and the constraints eliminated through the well-known Jacobian-based change of variables. As our first contribution in this work, we show that a much broader class of algebraic constraints can be collapsed by leveraging the properties of a Dirac delta model of deterministic constraints. Unfortunately, the collapsing process can lead to highly piecewise densities that pose challenges for existing probabilistic inference tools. Thus, our second contribution to address these challenges is to present a variation of Gibbs sampling that efficiently samples from these piecewise densities. The key insight to achieve this is to introduce a class of functions that 
(1) is sufficiently rich to approximate arbitrary models up to arbitrary precision, 
(2) is closed under dimension reduction for models with (non)linear algebraic constraints and 
(3) always permits one analytical integral â€” sufficient to automatically derive conditionals for Gibbs sampling in closed form. Our experimental results show that the proposed sampler converges at least an order of magnitude faster than existing Monte Carlo samplers.
\end{quote}
\end{abstract}