\begin{abstract}
  \begin{quote}
Probabilistic inference in many real-world problems requires graphical
models with deterministic algebraic constraints between random
variables (e.g., Newtonian mechanics, Pascal's law, Ohm's law) that
are known to be problematic for many inference methods such as Monte Carlo 
sampling.
%for many inference methods and hence it is desirable to collapse variables
%and remove them from the model.
%application of Gibbs sampling; we further show the collapsed model always
%permits one symbolic integral --- sufficient to
%automatically derive conditionals for Gibbs sampling.  We evaluate
%this fully automated Symbolic Gibbs sampler on models motivated by physics and
%engineering and show it converges an order of magnitude faster than
%existing Monte Carlo samplers.
Fortunately, when such constraints are invertible, the model can be
collapsed and the constraints eliminated through the well-known
Jacobian-based change of variables.  As our first contribution in this
work, we show that a much broader class of algebraic constraints can
be collapsed by leveraging the properties of a Dirac delta model of
deterministic constraints.  Unfortunately, the absolute values
introduced in this collapsing process can lead to highly piecewise
densities that pose challenges for existing probabilistic inference
tools.  Thus, our second contribution to address these challenges is
to present a variation of Gibbs sampling that efficiently samples from
these piecewise densities.
%via the closed-form derivation of conditional densities.
%handles piecewise
%densities and therefore works on constraint models in a purview that
%have remained beyond the tractability of the existing methods.
The key insight to achieve this is to introduce a class of functions
that (1)~is sufficiently rich to approximate arbitrary models up to
arbitrary precision, (2)~is closed under dimension reduction for
models with (non)linear algebraic constraints and (3)~always permits
one analytical integral --- sufficient to \emph{automatically} derive
conditionals for Gibbs sampling in closed form.
% While Gibbs sampling provides an attractive asymptotically unbiased MCMC approximation approach that does not require proposal design or tuning, it cannot be directly applied to models with determinism in the case of (1) and often requires manual derivation of complex piecewise conditional distributions in the case of (2).  To address both limitations, we introduce a rich class of piecewise algebraic graphical models with nonlinear determinism, where we show that deterministic constraints can always be eliminated through collapsing. We further show that the form of the collapsed model always permits one \emph{symbolic} integral --- sufficient to \emph{automatically} derive conditionals for Gibbs sampling.  We evaluate this fully automated Symbolic Gibbs sampler for nonlinear piecewise graphical models on examples motivated by physics and engineering and show it
Our experimental results show that the proposed sampler converges at
least an order of magnitude faster than existing Monte Carlo samplers.
\end{quote}
\end{abstract}
