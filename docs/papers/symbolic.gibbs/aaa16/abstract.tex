\begin{abstract}
\begin{quote}
In real-world applications of probabilistic reasoning, instead of random variables (non)linear functions of them (i.e.\ constraints over them) may be observed. 
%Except rare cases, inference cannot be directly performed on such models.
In case an observed constraint is a reversible function, the model can be handled via reducing the 
dimensionality of parameter space by Jacobian-based change of variable.
Using the properties of the Dirac delta, our first contribution is to propose a more general mechanism that does not require reversibility.   
Nevertheless, dimension reduction can lead to highly piecewise densities over which the performance of the existing inference tools can be unsatisfactory.   
Our second contribution is to present a variation of Gibbs sampling that efficiently handles piecewise densities and therefore works on constraint models in a purview that have remained beyond the tractability of the existing methods.
The key insight is to introduce a class of functions that (1)~is sufficiently rich to approximate arbitrary models up to arbitrary precision, (2)~is closed under dimension reduction for models with (non)linear algebraic constraints and (3)~always permits one analytical integral --- sufficient to \emph{automatically} derive conditionals for Gibbs sampling in closed form. 
% While Gibbs sampling provides an attractive asymptotically unbiased MCMC approximation approach that does not require proposal design or tuning, it cannot be directly applied to models with determinism in the case of (1) and often requires manual derivation of complex piecewise conditional distributions in the case of (2).  To address both limitations, we introduce a rich class of piecewise algebraic graphical models with nonlinear determinism, where we show that deterministic constraints can always be eliminated through collapsing. We further show that the form of the collapsed model always permits one \emph{symbolic} integral --- sufficient to \emph{automatically} derive conditionals for Gibbs sampling.  We evaluate this fully automated Symbolic Gibbs sampler for nonlinear piecewise graphical models on examples motivated by physics and engineering and show it
Our experimental results show that the proposed sampler 
converges at least an order of magnitude faster than existing Monte Carlo
samplers.
\end{quote}
\end{abstract}